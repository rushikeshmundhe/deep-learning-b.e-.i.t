# -*- coding: utf-8 -*-
"""pr2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10JXPLzt1P63pTUcbBPnV_kX8iJz02fPl
"""

from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.datasets import mnist

import matplotlib.pyplot as plt
import numpy as np

print("[INFO] accessing MNIST...")

((trainX, trainY), (testX, testY)) = mnist.load_data()

trainX = trainX.reshape((trainX.shape[0], 28 * 28 * 1))
testX = testX.reshape((testX.shape[0], 28 * 28 * 1))

trainX = trainX.astype("float32") / 255.0
testX = testX.astype("float32") / 255.0

lb = LabelBinarizer()
trainY = lb.fit_transform(trainY)
testY = lb.transform(testY)

model = Sequential()
model.add(Dense(256, input_shape=(784,), activation="relu"))
model.add(Dense(128, activation="relu"))
model.add(Dense(64, activation="relu"))
model.add(Dense(10, activation="softmax"))

print("[INFO] training network...")
Adm = Adam(0.01)
model.compile(loss="categorical_crossentropy", optimizer=Adm,
metrics=["accuracy"])
H = model.fit(trainX, trainY, validation_data=(testX, testY),
epochs=100, batch_size=128)

print("[INFO] evaluating network...")
predictions = model.predict(testX, batch_size=128)
print(classification_report(testY.argmax(axis=1),
  predictions.argmax(axis=1),
  target_names=[str(x) for x in lb.classes_]))

plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0, 100), H.history["loss"], label="train_loss")
plt.plot(np.arange(0, 100), H.history["val_loss"], label="val_loss")
plt.plot(np.arange(0, 100), H.history["accuracy"], label="train_acc")
plt.plot(np.arange(0, 100), H.history["val_accuracy"],
label="val_acc")
plt.title("Training Loss and Accuracy")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend()



'''
Sure, I can help you understand this code.

The code is written in Python and uses the TensorFlow and Keras libraries to train a neural network to classify handwritten digits from the MNIST dataset.

Here is a breakdown of the code:

**1. Import libraries**

The code starts by importing the necessary libraries. These libraries include:

* `sklearn.preprocessing`: This library provides tools for data preprocessing, including the LabelBinarizer class used in this code.
* `sklearn.metrics`: This library provides tools for evaluating the performance of machine learning models, including the classification_report function used in this code.
* `tensorflow.keras.models`: This library provides tools for creating and training neural networks.
* `tensorflow.keras.layers`: This library provides tools for creating different types of neural network layers.
* `tensorflow.keras.optimizers`: This library provides tools for optimizing the performance of neural networks during training.
* `tensorflow.keras.datasets`: This library provides access to pre-loaded datasets, including the MNIST dataset used in this code.
* `matplotlib.pyplot`: This library provides tools for creating plots.
* `numpy`: This library provides tools for working with numerical arrays.

**2. Load MNIST dataset**

The code then loads the MNIST dataset using the tensorflow.keras.datasets.mnist.load_data() function. The dataset is split into two parts: a training set and a test set. The training set is used to train the neural network, and the test set is used to evaluate the performance of the trained network.

**3. Preprocess data**

The code then preprocesses the data by reshaping the input images from 28x28x1 to 784x1 and converting the pixel values from integers to floating-point numbers. The code also applies label binarization to the target labels, which converts the integer labels into binary vectors.

**4. Define neural network model**

The code then defines the neural network model using the Sequential API from TensorFlow Keras. The model consists of four layers: an input layer with 784 units, two hidden layers with 256 and 128 units, respectively, and an output layer with 10 units.

**5. Train neural network**

The code then trains the neural network using the model.fit() function. The training process involves feeding the training data and labels to the model and adjusting the model's weights to minimize the loss function.

**6. Evaluate neural network**

The code then evaluates the performance of the trained neural network using the predict() function and the classification_report() function. The predict() function generates predictions for the test data, and the classification_report() function evaluates the accuracy of the predictions.

**7. Plot training and validation loss and accuracy**

The code finally plots the training and validation loss and accuracy over the course of the training process. This plot allows you to visualize how the model's performance improves over time.

I hope this explanation is helpful. Please let me know if you have any other questions.
'''
